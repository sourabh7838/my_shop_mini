import { createWriteStream } from 'node:fs';
import { basename } from 'node:path';
import http from 'node:http';
import { Storage } from '@google-cloud/storage';
import { PassThroughClient } from 'google-auth-library';
import { outputDebug } from '@shopify/cli-kit/node/output';
import { compare, parse } from 'semver';
import { PATHS } from '../../config.js';
import { isVersionAvailableLocally } from './binaries.js';
import { getLatestVersionFromFilesList, metadataToBinaryFileName, } from './version.js';
// TODO: set up domain and ssl certificate for cdn
// https://console.cloud.google.com/net-services/cdn/backendBucket/details/minis-app-builds-backend-bucket?project=arrive-167720
// https://console.cloud.google.com/storage/browser/minis_cli_app_builds
export const CDN_ADDRESS = 'http://34.160.57.53/';
export const GOOGLE_CLOUD_BUCKET_NAME = 'minis_cli_app_builds';
// Put bucket creation in to it's own function to make it easier to mock
const getBucket = () => {
    return new Storage({ authClient: new PassThroughClient() }).bucket(GOOGLE_CLOUD_BUCKET_NAME);
};
export const metadataToBucketPath = (metadata) => `${metadata.version}/${metadataToBinaryFileName(metadata)}`;
/**
 * Downloads a binary from the remote storage
 * @returns Promise that resolves to the downloaded version
 */
export async function downloadBinary(versionToDownload, { onProgress, } = {}) {
    outputDebug(`Downloading Shop app ${JSON.stringify(versionToDownload)}`);
    const isVersionAlreadyDownloaded = await isVersionAvailableLocally(versionToDownload);
    if (isVersionAlreadyDownloaded) {
        outputDebug(`Shop app version already downloaded`);
        onProgress?.(100);
        return versionToDownload;
    }
    const localFileName = metadataToBinaryFileName(versionToDownload);
    const remoteBucketPath = metadataToBucketPath(versionToDownload);
    let fileSize = 0;
    try {
        const [metadata] = await getBucket().file(remoteBucketPath).getMetadata();
        fileSize =
            typeof metadata.size === 'number'
                ? metadata.size
                : parseInt(metadata.size, 10);
        if (isNaN(fileSize)) {
            throw new Error('Invalid file size'); // the error message will be overwriten in the catch below anyway
        }
    }
    catch (err) {
        throw new Error(`Binary for version ${versionToDownload.version}+${versionToDownload.build} not found`);
    }
    return new Promise((resolve, reject) => {
        const writeStream = createWriteStream(`${PATHS.CACHE_DIR}/${localFileName}`);
        const progressInterval = setInterval(() => {
            const progress = Math.round((writeStream.bytesWritten / fileSize) * 100);
            onProgress?.(progress);
        }, 200);
        http.get(`${CDN_ADDRESS}${remoteBucketPath}`, cdnResponse => {
            cdnResponse.pipe(writeStream);
            writeStream.on('finish', () => {
                writeStream.close();
                outputDebug(`Shop app downloaded complete`);
                onProgress?.(100);
                resolve(versionToDownload);
                clearInterval(progressInterval);
            });
            writeStream.on('error', err => {
                outputDebug(`Shop app downloaded failed`);
                reject(err);
                clearInterval(progressInterval);
            });
        });
    });
}
/**
 * Returns the latest version that's present in the remote storage of binaries
 * TODO: this won't handle a bucket that has more than 50 files.
 */
export async function getLatestRemoteVersion(platform, type) {
    const versions = await getRemoteVersions();
    // newest first
    const sortedVersions = versions.sort(compare).reverse();
    // iterate over versions, in case newest version(s) don't contain builds for the given platform/type
    for (const version of sortedVersions) {
        const prefix = `${version}/`;
        const [filesMetadata] = await getBucket().getFiles({
            prefix,
        });
        const fileNames = filesMetadata
            .map(file => file.name)
            // extract filename from GCS bucket path
            .map(path => basename(path));
        const latestVersion = getLatestVersionFromFilesList(fileNames, platform, type);
        if (latestVersion != null) {
            return latestVersion;
        }
    }
    return null;
}
/**
 * Returns a list of all the versions that are present in the remote bucket,
 * regardless of platform or build type
 */
async function getRemoteVersions() {
    // GCS doesn't have a concept of 'folders', so we just list prefixes (which are the version numbers)
    // and remove the trailing delimiter ('/')
    let query = {
        delimiter: '/',
        // intentionally set to false to keep `apiResponse`
        // see: https://github.com/googleapis/google-cloud-node/issues/2594
        autoPaginate: false,
    };
    const prefixes = [];
    // loop to handle pagination
    do {
        const [_files, nextQuery, apiResponse] = await getBucket().getFiles(query);
        const newPrefixes = apiResponse.prefixes ?? [];
        prefixes.push(...newPrefixes);
        query = nextQuery;
    } while (query != null);
    return (prefixes
        // remove trailing delimiter
        .map(prefix => prefix.replace(/\/$/, ''))
        // validate that we only have 'x.y.z', not 'x.y.z-rc.1' or 'x.y.z+123'
        .filter(prefix => {
        const parsed = parse(prefix);
        return (parsed != null &&
            parsed.build.length === 0 &&
            parsed.prerelease.length === 0);
    }));
}
//# sourceMappingURL=network.js.map