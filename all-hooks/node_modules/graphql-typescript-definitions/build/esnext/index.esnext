import { EventEmitter } from 'events';
import { resolve, join } from 'path';
import { concatAST, parse, Source } from 'graphql';
import chalk from 'chalk';
import fsExtra from 'fs-extra';
import { loadConfigSync } from 'graphql-config';
import { getGraphQLSchemaPaths, getGraphQLProjects, getGraphQLProjectForSchemaPath, resolvePathRelativeToConfig } from 'graphql-config-utilities';
import { compile, isOperation } from 'graphql-tool-utilities';
export { EnumFormat, ExportFormat } from './types.esnext';
import { generateSchemaTypes } from './print/schema/index.esnext';
import { printDocument } from './print/document/index.esnext';
export { AbstractGraphQLFilesystem } from './filesystem/graphql-filesystem.esnext';

const {
  mkdirp,
  readFile,
  writeFile
} = fsExtra;
class Builder extends EventEmitter {
  // workspace graphql configuration
  // see: https://github.com/prisma/graphql-config

  // projectName -> {filePath -> document}
  // NOTE: projectName can be undefined for nameless graphql-config projects

  constructor({
    cwd,
    ...options
  }) {
    super();
    this.documentMapByProject = new Map();
    this.schemaCache = new Map();
    this.activeDocumentTypesJobId = 0;
    this.handleDocumentUpdate = async (filePath, projectConfig) => {
      try {
        await this.updateDocumentForFile(filePath, projectConfig);
      } catch (error) {
        this.emit('error', error);
        return;
      }
      await this.generateDocumentTypes();
    };
    this.handleDocumentDelete = async (filePath, projectConfig) => {
      const documents = this.documentMapByProject.get(projectConfig.name);
      if (documents) {
        documents.delete(filePath);
      }
      await this.generateDocumentTypes();
    };
    this.handleSchemaUpdate = async input => {
      const schemaPaths = typeof input === 'string' ? [input] : input;
      try {
        this.emit('start:schema');
        await Promise.all(schemaPaths.map(schemaPath => this.generateSchemaTypes(schemaPath)));
        this.emit('end:schema');
        await this.generateDocumentTypes();
      } catch (error) {
        // intentional noop
      }
    };
    this.options = options;
    const configPath = cwd ? resolve(cwd) : undefined;
    this.config = options.config ? options.config : loadConfigSync({
      rootDir: configPath
    });
  }
  once(event, handler) {
    return super.once(event, handler);
  }
  on(event, handler) {
    return super.on(event, handler);
  }
  emit(event, ...args) {
    return super.emit(event, ...args);
  }
  async run({
    watch: watchGlobs = false,
    graphQLFilesystem
  } = {}) {
    let schemaPaths;
    try {
      schemaPaths = getGraphQLSchemaPaths(this.config);
    } catch (error) {
      this.emit('error', error);
      return;
    }
    const filesystem = graphQLFilesystem !== null && graphQLFilesystem !== void 0 ? graphQLFilesystem : await defaultFilesytem();
    this.filesystem = filesystem;
    if (watchGlobs) {
      filesystem.on('change:document', this.handleDocumentUpdate).on('delete:document', this.handleDocumentDelete).on('change:schema', this.handleSchemaUpdate);

      // wait for all watchers to be ready
      await filesystem.watch(this.config);
    }
    try {
      this.emit('start:schema');
      await Promise.all(schemaPaths.map(schemaPath => this.generateSchemaTypes(schemaPath)));
      this.emit('end:schema');
    } catch (error) {
      this.emit('error', error);
      return;
    }
    try {
      await Promise.all(getGraphQLProjects(this.config).map(projectConfig => this.updateDocumentsForProject(filesystem, projectConfig)));
    } catch (error) {
      this.emit('error', error);
      return;
    }
    await this.generateDocumentTypes();
  }
  stop() {
    if (this.filesystem && typeof this.filesystem.dispose === 'function') {
      this.filesystem.dispose();
    }
  }
  async generateSchemaTypes(schemaPath) {
    const projectConfig = getGraphQLProjectForSchemaPath(this.config, schemaPath);
    const schemaTypesPath = getSchemaTypesPath(projectConfig, this.options);
    const definitions = generateSchemaTypes(await this.getSchema(projectConfig), this.options);
    await mkdirp(schemaTypesPath);
    await Promise.all(Array.from(definitions.entries()).map(([fileName, definition]) => writeFile(join(schemaTypesPath, fileName), definition)));
    this.emit('build:schema', {
      schemaPath,
      schemaTypesPath
    });
  }
  isDocumentTypesJobCancelled(jobId) {
    return this.activeDocumentTypesJobId !== jobId;
  }
  async generateDocumentTypes() {
    // Document generation can be called often via:
    // â€“ Projects with small + large schemas calling `handleSchemaUpdate`
    //   during schema refreshes
    // - Projects with many .graphql files triggering multiple
    //  `handleDocumentUpdate` calls during pulls (or rebases)
    //
    // The above scenarios do not provide a predictable debounce window that
    // would prevent multiple document generation jobs running, so generation
    // is allowed to immediately proceed, but each "job" checks itself often to
    // see if it should stop.
    const jobId = ++this.activeDocumentTypesJobId;
    return new Promise((resolve, reject) => {
      this.once('end:docs', () => {
        resolve();
      });
      this.once('error', () => reject());
      this._generateDocumentTypes(jobId).catch(err => reject(err));
    });
  }
  async _generateDocumentTypes(jobId) {
    this.emit('start:docs');
    this.checkForDuplicateOperations();
    this.checkForDuplicateFragments();
    await Promise.all(Array.from(this.documentMapByProject.entries()).map(([projectName, documents]) => this.generateDocumentTypesForProject(this.config.getProject(projectName), documents, jobId)));
    if (this.isDocumentTypesJobCancelled(jobId)) return;
    this.emit('end:docs');
  }
  checkForDuplicateOperations() {
    getDuplicateOperations(this.documentMapByProject).forEach(({
      projectName,
      duplicates
    }) => {
      if (duplicates.length) {
        duplicates.forEach(({
          operationName,
          filePaths
        }) => {
          const message = `GraphQL operations must have a unique name. The operation ${chalk.bold(operationName)} is declared in:\n ${filePaths.sort().join('\n ')}${projectName ? ` (${chalk.bold(projectName)})` : ''}`;
          this.emit('error', new Error(message));
        });
      }
    });
  }
  checkForDuplicateFragments() {
    getDuplicateFragments(this.documentMapByProject).forEach(({
      projectName,
      duplicates
    }) => {
      if (duplicates.length) {
        duplicates.forEach(({
          fragmentName,
          filePaths
        }) => {
          const message = `GraphQL fragments must have a unique name. The fragment ${chalk.bold(fragmentName)} is declared in:\n ${filePaths.sort().join('\n ')}${projectName ? ` (${chalk.bold(projectName)})` : ''}`;
          this.emit('error', new Error(message));
        });
      }
    });
  }
  async generateDocumentTypesForProject(projectConfig, documents, jobId) {
    let ast;
    if (this.isDocumentTypesJobCancelled(jobId)) return;
    try {
      ast = compile(await this.getSchema(projectConfig), concatAST(Array.from(documents.values())));
    } catch (error) {
      this.emit('error', error);
      return;
    }
    if (this.isDocumentTypesJobCancelled(jobId)) return;
    try {
      for (const file of groupOperationsAndFragmentsByFile(ast).values()) {
        if (this.isDocumentTypesJobCancelled(jobId)) return;
        await this.writeDocumentFile(file, ast, projectConfig);
      }
    } catch (error) {
      // intentional noop
    }
  }
  async writeDocumentFile(file, ast, projectConfig) {
    const definitionPath = `${file.path}.d.ts`;
    await writeFile(definitionPath, this.getDocumentDefinition(file, ast, projectConfig));
    this.emit('build:docs', {
      documentPath: file.path,
      definitionPath,
      operation: file.operation,
      fragments: file.fragments
    });
  }
  getDocumentDefinition(file, ast, projectConfig) {
    try {
      return printDocument(file, ast, {
        enumFormat: this.options.enumFormat,
        exportFormat: this.options.exportFormat,
        addTypename: this.options.addTypename,
        schemaTypesPath: getSchemaTypesPath(projectConfig, this.options)
      });
    } catch ({
      message
    }) {
      const error = new Error(`Error in ${file.path}: ${message[0].toLowerCase()}${message.slice(1)}`);
      this.emit('error', error);
      throw error;
    }
  }
  async updateDocumentsForProject(filesystem, projectConfig) {
    const filePaths = await filesystem.getGraphQLProjectIncludedFilePaths(projectConfig);
    return Promise.all(filePaths.map(filePath => this.updateDocumentForFile(filePath, projectConfig)));
  }
  async updateDocumentForFile(filePath, projectConfig) {
    const contents = await readFile(filePath, 'utf8');
    return this.setDocumentForFilePath(filePath, projectConfig, contents);
  }
  setDocumentForFilePath(filePath, projectConfig, contents) {
    let documents = this.documentMapByProject.get(projectConfig.name);
    if (!documents) {
      documents = new Map();
      this.documentMapByProject.set(projectConfig.name, documents);
    }
    if (contents.trim().length === 0) {
      return undefined;
    }
    const document = parse(new Source(contents, filePath));
    documents.set(filePath, document);
    return document;
  }
  getSchema(projectConfig) {
    const {
      name
    } = projectConfig;
    if (!this.schemaCache.has(name)) {
      const schemaPromise = projectConfig.getSchema();
      this.schemaCache.set(name, schemaPromise);
    }
    return this.schemaCache.get(name);
  }
}
function getSchemaTypesPath(projectConfig, options) {
  if (typeof projectConfig.extensions.schemaTypesPath === 'string') {
    return resolvePathRelativeToConfig(projectConfig, projectConfig.extensions.schemaTypesPath);
  }
  return resolvePathRelativeToConfig(projectConfig, join(options.schemaTypesPath, `${projectConfig.name ? `${projectConfig.name}-` : ''}types`));
}
async function defaultFilesytem() {
  const {
    DefaultGraphQLFilesystem
  } = await import('./filesystem/default-graphql-filesystem.esnext');
  return new DefaultGraphQLFilesystem();
}
function groupOperationsAndFragmentsByFile({
  operations,
  fragments
}) {
  return Object.values(operations).concat(Object.values(fragments)).reduce((map, item) => {
    if (!item.filePath) {
      return map;
    }
    let file = map.get(item.filePath);
    if (!file) {
      file = {
        path: item.filePath,
        operation: undefined,
        fragments: []
      };
      map.set(item.filePath, file);
    }
    if (isOperation(item)) {
      file.operation = item;
    } else {
      file.fragments.push(item);
    }
    return map;
  }, new Map());
}
function getDuplicateOperations(documentsMapByProject) {
  return Array.from(documentsMapByProject.entries()).map(([projectName, documents]) => {
    return {
      projectName,
      duplicates: getDuplicateProjectOperations(documents)
    };
  });
}
function getDuplicateFragments(documentsMapByProject) {
  return Array.from(documentsMapByProject.entries()).map(([projectName, documents]) => {
    return {
      projectName,
      duplicates: getDuplicateProjectFragments(documents)
    };
  });
}
function getDuplicateProjectOperations(documents) {
  const operations = new Map();
  Array.from(documents.entries()).forEach(([filePath, document]) => {
    document.definitions.filter(isOperationDefinition).forEach(definition => {
      const {
        name
      } = definition;
      if (name && name.value) {
        const map = operations.get(name.value);
        if (map) {
          map.add(filePath);
        } else {
          operations.set(name.value, new Set([filePath]));
        }
      }
    });
  });
  return Array.from(operations.entries()).filter(([, filePaths]) => filePaths.size > 1).map(([operationName, filePath]) => {
    return {
      operationName,
      filePaths: Array.from(filePath)
    };
  });
}
function getDuplicateProjectFragments(documents) {
  const fragments = new Map();
  Array.from(documents.entries()).forEach(([filePath, document]) => {
    document.definitions.filter(isFragmentDefinition).forEach(definition => {
      const {
        name
      } = definition;
      if (name && name.value) {
        const map = fragments.get(name.value);
        if (map) {
          map.add(filePath);
        } else {
          fragments.set(name.value, new Set([filePath]));
        }
      }
    });
  });
  return Array.from(fragments.entries()).filter(([, filePaths]) => filePaths.size > 1).map(([fragmentName, filePath]) => {
    return {
      fragmentName,
      filePaths: Array.from(filePath)
    };
  });
}
function isOperationDefinition(definition) {
  return definition.kind === 'OperationDefinition';
}
function isFragmentDefinition(definition) {
  return definition.kind === 'FragmentDefinition';
}

export { Builder };
